{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9401942,"sourceType":"datasetVersion","datasetId":5707438},{"sourceId":104449,"sourceType":"modelInstanceVersion","modelInstanceId":68809,"modelId":91102}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ******************************* 0 ******************************* \n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-21T09:01:07.583162Z","iopub.execute_input":"2024-09-21T09:01:07.583876Z","iopub.status.idle":"2024-09-21T09:01:07.960137Z","shell.execute_reply.started":"2024-09-21T09:01:07.583800Z","shell.execute_reply":"2024-09-21T09:01:07.959186Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/combined-data/combines_dataset.csv\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model.safetensors.index.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00003-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/LICENSE\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00001-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/README.md\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/USE_POLICY.md\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer_config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00004-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/special_tokens_map.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/.gitattributes\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00002-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/generation_config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/consolidated.00.pth\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/params.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/tokenizer.model\n","output_type":"stream"}]},{"cell_type":"code","source":"# Necessary until transformers package is updated in the Kaggle notebook environment.\n!pip install --upgrade transformers\n\nimport transformers\nimport torch\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\nmodel = \"/kaggle/input/llama-3.1/transformers/8b/1\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline = transformers.pipeline(\n    \"text-generation\", model=model,max_length = 2048, model_kwargs={\"torch_dtype\": torch.bfloat16}, device_map=\"auto\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline('''Generate 15 MCQs from the following passage of different difficulty levels. \nThe questions should be of easy, medium and hard difficulty level, where each difficulty level should have 5 questions each.\nHorticulture Growing vegetables, flowers and fruits for commercial use.\nFarm System Agriculture or farming can be looked at as a system. The important inputs are\nseeds, fertilisers, machinery and labour. Some of the operations involved are ploughing, sowing,\nirrigation, weeding and harvesting. The outputs from the system include crops, wool, dairy and\npoultry products. Types of Farming Farming is practised in various ways across the world.\nDepending upon the geographical conditions, demand of produce, labour and level of\ntechnology, farming can be classified into two main types. These are subsistence farming and\ncommercial farming. Subsistence Farming This type of farming is practised to meet the needs of\nthe farmer‚Äôs family. Traditionally, low levels of technology and household labour are used to\nproduce on small output. Subsistence farming can be further classified as intensive subsistence\nand primitive subsistence farming. In intensive subsistence agriculture the farmer cultivates a\nsmall plot of land using simple tools and more labour. Climate with large number of days with\nsunshine and fertile soils permit growing of more than one crop annually on the same plot. Rice\nis the main crop. Other crops include wheat, maize, pulses and oilseeds. Intensive subsistence\nagriculture is prevalent in the thickly populated areas of the monsoon regions of south,\nsoutheast and east Asia. Primitive subsistence agriculture includes shifting cultivation and\nnomadic herding. Shifting cultivation is practised in the thickly forested areas of Amazon basin,\ntropical Africa, parts of southeast Asia and Northeast India. These are the areas of heavy\nrainfall and quick regeneration of vegetation. A plot of land is cleared by felling the trees and\nburning them. The ashes are then mixed with the soil and crops like maize, yam, potatoes and\ncassava are grown. After the soil loses its fertility, the land is abandoned and the cultivator\nmoves to a new plot. Shifting cultivation is also known as ‚Äòslash and burn‚Äô agriculture. Nomadic\nherding is practised in the semi-arid and arid regions of Sahara, Central Asia and some parts of\nIndia, like Rajasthan and Jammu and Kashmir. In this type of farming, herdsmen move from\nplace to place with their animals for fodder and water, along defined routes. This type of\nmovement arises in response to climatic constraints and terrain. Sheep, camel, yak and goatsare most commonly reared. They provide milk, meat, wool, hides and other products to the\nherders and their families.\n''',max_length = 2048)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Llama 3.1 8B-Instruct","metadata":{}},{"cell_type":"code","source":"passage = '''Horticulture Growing vegetables, flowers and fruits for commercial use.\nFarm System Agriculture or farming can be looked at as a system. The important inputs are\nseeds, fertilisers, machinery and labour. Some of the operations involved are ploughing, sowing,\nirrigation, weeding and harvesting. The outputs from the system include crops, wool, dairy and\npoultry products. Types of Farming Farming is practised in various ways across the world.\nDepending upon the geographical conditions, demand of produce, labour and level of\ntechnology, farming can be classified into two main types. These are subsistence farming and\ncommercial farming. Subsistence Farming This type of farming is practised to meet the needs of\nthe farmer‚Äôs family. Traditionally, low levels of technology and household labour are used to\nproduce on small output. Subsistence farming can be further classified as intensive subsistence\nand primitive subsistence farming. In intensive subsistence agriculture the farmer cultivates a\nsmall plot of land using simple tools and more labour. Climate with large number of days with\nsunshine and fertile soils permit growing of more than one crop annually on the same plot. Rice\nis the main crop. Other crops include wheat, maize, pulses and oilseeds. Intensive subsistence\nagriculture is prevalent in the thickly populated areas of the monsoon regions of south,\nsoutheast and east Asia. Primitive subsistence agriculture includes shifting cultivation and\nnomadic herding. Shifting cultivation is practised in the thickly forested areas of Amazon basin,\ntropical Africa, parts of southeast Asia and Northeast India. These are the areas of heavy\nrainfall and quick regeneration of vegetation. A plot of land is cleared by felling the trees and\nburning them. The ashes are then mixed with the soil and crops like maize, yam, potatoes and\ncassava are grown. After the soil loses its fertility, the land is abandoned and the cultivator\nmoves to a new plot. Shifting cultivation is also known as ‚Äòslash and burn‚Äô agriculture. Nomadic\nherding is practised in the semi-arid and arid regions of Sahara, Central Asia and some parts of\nIndia, like Rajasthan and Jammu and Kashmir. In this type of farming, herdsmen move from\nplace to place with their animals for fodder and water, along defined routes. This type of\nmovement arises in response to climatic constraints and terrain. Sheep, camel, yak and goatsare most commonly reared. They provide milk, meat, wool, hides and other products to the\nherders and their families.'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Necessary until transformers packages is updated in the Kaggle notebook environment.\n!pip install --upgrade transformers\n\nimport transformers\nimport torch\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\nmodel_id = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model_id,\n    model_kwargs={\"torch_dtype\": torch.bfloat16},\n    device_map=\"auto\",\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = '''Today you have to conduct a MCQ based test on a given topic. For the test generate 15 MCQs from the following passage with the answer key.\nThe Test consists of three different sections where each section contains 5 questions each of easy, medium and hard difficulty level.\nUse Bloom's Taxonomy to define the difficulty level of the question.\nRemember the questions should be from the passage only. '''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are an assitant social studies teacher in a High School.\"},\n    {\"role\": \"user\", \"content\": prompt + passage},\n]\n\noutputs = pipeline(\n    messages,\n    max_new_tokens=2048,\n)\nprint(outputs[0][\"generated_text\"][-1])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generated MCQS on ","metadata":{}},{"cell_type":"markdown","source":"\"**Section 1: Recall (Easy Difficulty Level)**\\n\\n1. What is Horticulture?\\n   a) Growing vegetables, flowers and fruits for commercial use\\n   b) Farming for subsistence\\n   c) Farming for commercial use\\n   d) Growing crops for household use\\n\\nAnswer: a) Growing vegetables, flowers and fruits for commercial use\\n\\n2. What are the important inputs in a farm system?\\n   a) Seeds, fertilisers, machinery and labour\\n   b) Seeds, fertilisers, animals and soil\\n   c) Seeds, labour, machinery and water\\n   d) Seeds, fertilisers, animals and tools\\n\\nAnswer: a) Seeds, fertilisers, machinery and labour\\n\\n3. What are the outputs from a farm system?\\n   a) Crops, wool, dairy and poultry products\\n   b) Crops, seeds, fertilisers and labour\\n   c) Crops, animals, tools and water\\n   d) Crops, animals, seeds and soil\\n\\nAnswer: a) Crops, wool, dairy and poultry products\\n\\n4. What is subsistence farming?\\n   a) Farming to meet the needs of the farmer's family\\n   b) Farming for commercial use\\n   c) Farming for household use\\n   d) Farming for export\\n\\nAnswer: a) Farming to meet the needs of the farmer's family\\n\\n5. What is intensive subsistence agriculture?\\n   a) Farming using simple tools and more labour\\n   b) Farming using complex tools and less labour\\n   c) Farming using animals and household labour\\n   d) Farming using machines and commercial labour\\n\\nAnswer: a) Farming using simple tools and more labour\\n\\n\n**Section 2: Analyze (Medium Difficulty Level)**\\n\\n6. What are the geographical conditions that permit intensive subsistence agriculture? (Bloom's Taxonomy: Analyze)\\n   a) Large number of days with sunshine and fertile soils\\n   b) Heavy rainfall and quick regeneration of vegetation\\n   c) Semi-arid and arid regions\\n   d) Thickly populated areas\\n\\nAnswer: a) Large number of days with sunshine and fertile soils\\n\\n7. What are the main crops grown in intensive subsistence agriculture? (Bloom's Taxonomy: Analyze)\\n   a) Rice, wheat, maize, pulses and oilseeds\\n   b) Maize, yam, potatoes and cassava\\n   c) Sheep, camel, yak and goats\\n   d) Cattle, buffalo and horses\\n\\nAnswer: a) Rice, wheat, maize, pulses and oilseeds\\n\\n8. What is shifting cultivation? (Bloom's Taxonomy: Analyze)\\n   a) Farming using simple tools and more labour\\n   b) Farming using animals and household labour\\n   c) Shifting from one plot of land to another\\n   d) Farming using machines and commercial labour\\n\\nAnswer: c) Shifting from one plot of land to another\\n\\n9. What is nomadic herding? (Bloom's Taxonomy: Analyze)\\n   a) Farming using simple tools and more labour\\n   b) Farming using animals and household labour\\n   c) Moving from place to place with animals for fodder and water\\n   d) Farming using machines and commercial labour\\n\\nAnswer: c) Moving from place to place with animals for fodder and water\\n\\n10. What are the products provided by sheep, camel, yak and goats in nomadic herding? (Bloom's Taxonomy: Analyze)\\n    a) Milk, meat, wool, hides and other products\\n    b) Crops, seeds, fertilisers and labour\\n    c) Crops, animals, tools and water\\n    d) Crops, animals, seeds and soil\\n\\nAnswer: a) Milk, meat, wool, hides and other products\\n\\n\n**Section 3: Evaluate (Hard Difficulty Level)**\\n\\n11. What are the limitations of subsistence farming? (Bloom's Taxonomy: Evaluate)\\n    a) Low levels of technology and household labour\\n    b) High levels of technology and commercial labour\\n    c) Large number of days with sunshine and fertile soils\\n    d) Heavy rainfall and quick regeneration of vegetation\\n\\nAnswer: a) Low levels of technology and household labour\\n\\n12. What are the advantages of intensive subsistence agriculture? (Bloom's Taxonomy: Evaluate)\\n    a) High levels of technology and commercial labour\\n    b) Low levels of technology and household labour\\n    c) Large number of days with sunshine and fertile soils\\n    d) Heavy rainfall and quick regeneration of vegetation\\n\\nAnswer: c) Large number of days with sunshine and fertile soils\\n\\n13. What are the limitations of shifting cultivation? (Bloom's Taxonomy: Evaluate)\\n    a) Soil loses its fertility and is abandoned\\n    b) Soil retains its fertility and is reused\\n    c) Large number of days with sunshine and fertile soils\\n    d) Heavy rainfall and quick regeneration of vegetation\\n\\nAnswer: a) Soil loses its fertility and is abandoned\\n\\n14. What are the advantages of nomadic herding? (Bloom's Taxonomy: Evaluate)\\n    a) High levels of technology and commercial labour\\n    b) Low levels of technology and household labour\\n    c) Moving from place to place with animals for fodder and water\\n    d) Farming using machines and commercial labour\\n\\nAnswer: c) Moving from place to place with animals for fodder and water\\n\\n15. What are the geographical conditions that permit nomadic herding? (Bloom's Taxonomy: Evaluate)\\n    a) Large number of days with sunshine and fertile soils\\n    b) Heavy rainfall and quick regeneration of vegetation\\n    c) Semi-arid and arid regions\\n    d) Thickly populated areas\\n\\nAnswer: c) Semi-arid and arid regions\"}","metadata":{}},{"cell_type":"markdown","source":"# Fine-Tuning","metadata":{}},{"cell_type":"markdown","source":"## Using ADALORA\n","metadata":{}},{"cell_type":"code","source":"# ******************************* 0.1 ******************************* \n!pip install -U bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:01:26.455515Z","iopub.execute_input":"2024-09-21T09:01:26.456374Z","iopub.status.idle":"2024-09-21T09:01:43.473947Z","shell.execute_reply.started":"2024-09-21T09:01:26.456330Z","shell.execute_reply":"2024-09-21T09:01:43.472811Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Using cached bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nUsing cached bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\nInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.3\n","output_type":"stream"}]},{"cell_type":"code","source":"# ******************************* 0.2 ******************************* \nimport bitsandbytes as bnb\nprint(bnb.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:01:43.477858Z","iopub.execute_input":"2024-09-21T09:01:43.478202Z","iopub.status.idle":"2024-09-21T09:01:49.078057Z","shell.execute_reply.started":"2024-09-21T09:01:43.478168Z","shell.execute_reply":"2024-09-21T09:01:49.077062Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"0.43.3\n","output_type":"stream"}]},{"cell_type":"code","source":"# ******************************* 0.3 ******************************* \n!pip install transformers\n!pip install peft  # This is for Parameter-Efficient Fine-Tuning (PEFT)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:01:49.079342Z","iopub.execute_input":"2024-09-21T09:01:49.079800Z","iopub.status.idle":"2024-09-21T09:02:17.166379Z","shell.execute_reply.started":"2024-09-21T09:01:49.079765Z","shell.execute_reply":"2024-09-21T09:02:17.165159Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nCollecting peft\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.44.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.33.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.4)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.24.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"model_id = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:02:17.169647Z","iopub.execute_input":"2024-09-21T09:02:17.170392Z","iopub.status.idle":"2024-09-21T09:02:17.174652Z","shell.execute_reply.started":"2024-09-21T09:02:17.170355Z","shell.execute_reply":"2024-09-21T09:02:17.173816Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Necessary until transformers packages is updated in the Kaggle notebook environment.\n!pip install --upgrade transformers\n\nimport transformers\nimport torch\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\n\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model_id,\n    model_kwargs={\"torch_dtype\": torch.bfloat16},\n    device_map=\"auto\",\n)\n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-09-21T09:01:00.927819Z","iopub.status.idle":"2024-09-21T09:01:00.928191Z","shell.execute_reply.started":"2024-09-21T09:01:00.928020Z","shell.execute_reply":"2024-09-21T09:01:00.928038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = pipeline.model","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:01:00.929687Z","iopub.status.idle":"2024-09-21T09:01:00.930069Z","shell.execute_reply.started":"2024-09-21T09:01:00.929881Z","shell.execute_reply":"2024-09-21T09:01:00.929900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adalora\n\nfrom peft import AdaLoraConfig, AdaLoraModel\n\nadalora_config = AdaLoraConfig(\n    task_type=\"CAUSAL_LM\",\n    inference_mode=False,\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1\n)\n\nmodel = AdaLoraModel(model, adalora_config, \"default\")\n\n# number of trainable parameters\nnum_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n#total number of parameters\ntotal_params = sum(p.numel() for p in model.parameters())\n\n# percentage of trainable parameters\npercentage_trainable_params = (num_trainable_params / total_params) * 100\n\nprint(\"Number of trainable parameters:\", num_trainable_params)\nprint(\"Total number of parameters:\", total_params)\nprint(\"Percentage of trainable parameters:\", percentage_trainable_params)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-09-21T09:01:00.931723Z","iopub.status.idle":"2024-09-21T09:01:00.932097Z","shell.execute_reply.started":"2024-09-21T09:01:00.931910Z","shell.execute_reply":"2024-09-21T09:01:00.931928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# loading dataset","metadata":{}},{"cell_type":"code","source":"# ******************************* 1 ******************************* \nimport pandas as pd\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/combined-data/combines_dataset.csv', encoding='ISO-8859-1')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:02:17.176114Z","iopub.execute_input":"2024-09-21T09:02:17.176785Z","iopub.status.idle":"2024-09-21T09:02:17.260599Z","shell.execute_reply.started":"2024-09-21T09:02:17.176741Z","shell.execute_reply":"2024-09-21T09:02:17.259810Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# ******************************* 1.1 ******************************* \n# Display the first few rows\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:02:17.261769Z","iopub.execute_input":"2024-09-21T09:02:17.262065Z","iopub.status.idle":"2024-09-21T09:02:17.291133Z","shell.execute_reply.started":"2024-09-21T09:02:17.262034Z","shell.execute_reply":"2024-09-21T09:02:17.290277Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                             passage  \\\n0  This transformation from a plant to a finished...   \n1  People are a nation√¢¬Ä¬ôs greatest resource. Nat...   \n2  Have you ever given a thought to the fact that...   \n3  In a small village in Tanzania, Africa, Mamba ...   \n4  Water, electricity, rickshaw, vegetable and te...   \n\n                                                mcqs  \n0  ['## Agriculture and Economic Activities: An M...  \n1  ['## Population Studies Test\\n', '\\n', '**Inst...  \n2  ['## The Journey of Your Notebook: A Social St...  \n3  ['## Social Studies Test: Land as a Resource\\n...  \n4  ['## Agriculture and Farming: An MCQ Test\\n', ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>passage</th>\n      <th>mcqs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This transformation from a plant to a finished...</td>\n      <td>['## Agriculture and Economic Activities: An M...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>People are a nation√¢¬Ä¬ôs greatest resource. Nat...</td>\n      <td>['## Population Studies Test\\n', '\\n', '**Inst...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Have you ever given a thought to the fact that...</td>\n      <td>['## The Journey of Your Notebook: A Social St...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>In a small village in Tanzania, Africa, Mamba ...</td>\n      <td>['## Social Studies Test: Land as a Resource\\n...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Water, electricity, rickshaw, vegetable and te...</td>\n      <td>['## Agriculture and Farming: An MCQ Test\\n', ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# ******************************* 1.3 ******************************* \n# Import the splitting function\nfrom sklearn.model_selection import train_test_split\n\n# Split the formatted data into training and testing sets\ntrain_data, test_data = train_test_split(df, test_size=0.3, random_state=42)\n\n# Check the lengths of the train and test splits\nprint(f\"Training set size: {len(train_data)}\")\nprint(f\"Testing set size: {len(test_data)}\")\n\n# Optional: Print the first entry from the training and test set\nprint(f\"First training example: {train_data.iloc[0]}\")\nprint(len(train_data),\"\\n\")\nprint(f\"First testing example: {test_data.iloc[0]}\")\nprint(len(test_data))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:02:17.292389Z","iopub.execute_input":"2024-09-21T09:02:17.292777Z","iopub.status.idle":"2024-09-21T09:02:17.992266Z","shell.execute_reply.started":"2024-09-21T09:02:17.292733Z","shell.execute_reply":"2024-09-21T09:02:17.991238Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Training set size: 100\nTesting set size: 43\nFirst training example: passage    European Imperialism The American empires of S...\nmcqs       ['## European Imperialism - MCQ Test\\n', '\\n',...\nName: 84, dtype: object\n100 \n\nFirst testing example: passage    1. A Mosaic of Religious Beliefs and Practices...\nmcqs       ['## MCQ Test: A Mosaic of Religious Beliefs\\n...\nName: 117, dtype: object\n43\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = train_data.reset_index(drop=True)\ntest_data = test_data.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:02:17.993602Z","iopub.execute_input":"2024-09-21T09:02:17.994201Z","iopub.status.idle":"2024-09-21T09:02:17.999550Z","shell.execute_reply.started":"2024-09-21T09:02:17.994153Z","shell.execute_reply":"2024-09-21T09:02:17.998563Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"passages = train_data['passage'].tolist()\nmcqs = train_data['mcqs'].tolist()\n\npassage_test = test_data['passage'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:02:18.000695Z","iopub.execute_input":"2024-09-21T09:02:18.000997Z","iopub.status.idle":"2024-09-21T09:02:18.009339Z","shell.execute_reply.started":"2024-09-21T09:02:18.000958Z","shell.execute_reply":"2024-09-21T09:02:18.008497Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# ******************************* 1.2 ******************************* \ntrain_data = []\n\nfor passage, mcq in zip(passages, mcqs):\n    formatted_entry = (\n        \"<|begin_of_text|> \"\n        \"<|start_header_id|>passage<|end_header_id|> \" + passage.strip() + \" \"\n        \"<|eom_id|> \"\n        \"<|start_header_id|>questions<|end_header_id|> \" + mcq.strip() + \" \"\n        \"<|eot_id|> \"\n        \"<|end_of_text|>\"\n    )\n\n    train_data.append(formatted_entry)\n\n# print(formatted_data[72])","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:02:18.012361Z","iopub.execute_input":"2024-09-21T09:02:18.012704Z","iopub.status.idle":"2024-09-21T09:02:18.020899Z","shell.execute_reply.started":"2024-09-21T09:02:18.012673Z","shell.execute_reply":"2024-09-21T09:02:18.020189Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# ******************************* 1.3 ******************************* \nevaluation_data = []\n\nfor passage in (passage_test):\n    formatted_entry = (\n        \"<|begin_of_text|> \"\n        \"<|start_header_id|>passage<|end_header_id|> \" + passage.strip() + \" \"\n        \"<|eom_id|> \"\n        \"<|start_header_id|>questions<|end_header_id|> \"\n        \"<|eot_id|> \"\n        \"<|end_of_text|>\"\n    )\n\n\n    evaluation_data.append(formatted_entry)\n\n# print(evaluation_data[0])","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:02:18.022076Z","iopub.execute_input":"2024-09-21T09:02:18.022362Z","iopub.status.idle":"2024-09-21T09:02:18.030540Z","shell.execute_reply.started":"2024-09-21T09:02:18.022331Z","shell.execute_reply":"2024-09-21T09:02:18.029644Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import LlamaForCausalLM, BitsAndBytesConfig\nfrom peft import get_peft_model, LoraConfig\n\n# Define a BitsAndBytesConfig for 4-bit quantization\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,  # Enable 4-bit quantization\n    bnb_4bit_quant_type=\"nf4\",  # You can choose \"fp4\" or \"nf4\"\n    bnb_4bit_use_double_quant=True,  # Optional: Use double quantization for better precision\n    bnb_4bit_compute_dtype=\"float16\"  # Set compute to float16 to save memory\n)\n\n# Load the model with the new quantization config\nmodel = LlamaForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=quantization_config,  # Use BitsAndBytesConfig for quantization\n    device_map='auto'  # Automatically map the model to available devices (e.g., GPU)\n)\n\n# Apply LoRA (Low-Rank Adaptation)\nlora_config = LoraConfig(\n    r=8,  # Low-rank dimension\n    lora_alpha=32,  # Scaling factor\n    lora_dropout=0.1,  # Dropout for LoRA layers\n    target_modules=[\"q_proj\", \"v_proj\"]  # Target layers for LoRA adaptation\n)\n\n# Wrap the model with QLoRA (Quantized Low-Rank Adaptation)\nmodel = get_peft_model(model, lora_config)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:02:18.031753Z","iopub.execute_input":"2024-09-21T09:02:18.032423Z","iopub.status.idle":"2024-09-21T09:03:48.646334Z","shell.execute_reply.started":"2024-09-21T09:02:18.032379Z","shell.execute_reply":"2024-09-21T09:03:48.645536Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4b788b688ac49158e9e4e7c5bf25b34"}},"metadata":{}}]},{"cell_type":"code","source":"# ******************************* 2.1 ******************************* \nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/llama-3.1/transformers/8b-instruct/2/\")\ntokenizer.add_special_tokens({\n    'pad_token': '[PAD]',\n    'additional_special_tokens': ['<begin_of_text>', '<start_header_id>', '<end_header_id>', '<eom_id>', '<eot_id>', '<end_of_text>']\n})\n","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:04:11.093651Z","iopub.execute_input":"2024-09-21T09:04:11.094248Z","iopub.status.idle":"2024-09-21T09:04:11.647891Z","shell.execute_reply.started":"2024-09-21T09:04:11.094203Z","shell.execute_reply":"2024-09-21T09:04:11.646876Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"7"},"metadata":{}}]},{"cell_type":"code","source":"model.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:04:12.638053Z","iopub.execute_input":"2024-09-21T09:04:12.638441Z","iopub.status.idle":"2024-09-21T09:04:12.772546Z","shell.execute_reply.started":"2024-09-21T09:04:12.638404Z","shell.execute_reply":"2024-09-21T09:04:12.771627Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Embedding(128263, 4096)"},"metadata":{}}]},{"cell_type":"code","source":"# ******************************* 3 ******************************* \nfrom torch.utils.data import Dataset\n\nclass TextGenerationDataset(Dataset):\n    def __init__(self, formatted_data, tokenizer, max_length=1024):\n        self.formatted_data = formatted_data\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.formatted_data)\n\n    def __getitem__(self, idx):\n        # Get the formatted entry\n        formatted_entry = self.formatted_data[idx]\n        \n        \n        # Tokenize the entire formatted entry\n        encoding = self.tokenizer(\n            formatted_entry,\n            return_tensors='pt',\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True\n        )\n\n        # Extract input_ids and create labels\n        input_ids = encoding['input_ids'].squeeze()\n        labels = input_ids.clone() \n\n        return {'input_ids': input_ids, 'labels': labels}\n\n# Prepare the dataset using the new formatted data\ntrain_dataset = TextGenerationDataset(train_data, tokenizer)\ntest_dataset =  TextGenerationDataset(evaluation_data, tokenizer)\n\n# Define the DataLoader if needed\n# train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)  # Adjust batch size as needed","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:04:14.357721Z","iopub.execute_input":"2024-09-21T09:04:14.358521Z","iopub.status.idle":"2024-09-21T09:04:14.366188Z","shell.execute_reply.started":"2024-09-21T09:04:14.358481Z","shell.execute_reply":"2024-09-21T09:04:14.365348Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# ******************************* 3.1 ******************************* \nimport torch\nprint(torch.cuda.device_count())  ","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:04:18.998704Z","iopub.execute_input":"2024-09-21T09:04:18.999578Z","iopub.status.idle":"2024-09-21T09:04:19.004320Z","shell.execute_reply.started":"2024-09-21T09:04:18.999538Z","shell.execute_reply":"2024-09-21T09:04:19.003337Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"2\n","output_type":"stream"}]},{"cell_type":"code","source":"# ******************************* 3.2 ******************************* \nimport torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:04:19.262272Z","iopub.execute_input":"2024-09-21T09:04:19.262610Z","iopub.status.idle":"2024-09-21T09:04:19.266868Z","shell.execute_reply.started":"2024-09-21T09:04:19.262577Z","shell.execute_reply":"2024-09-21T09:04:19.266019Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Verify the type of datasets\nprint(type(train_dataset))\nprint(type(test_dataset))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:04:19.777901Z","iopub.execute_input":"2024-09-21T09:04:19.778572Z","iopub.status.idle":"2024-09-21T09:04:19.783701Z","shell.execute_reply.started":"2024-09-21T09:04:19.778536Z","shell.execute_reply":"2024-09-21T09:04:19.782726Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"<class '__main__.TextGenerationDataset'>\n<class '__main__.TextGenerationDataset'>\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(train_dataset))\n\nprint(len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:04:21.673671Z","iopub.execute_input":"2024-09-21T09:04:21.674649Z","iopub.status.idle":"2024-09-21T09:04:21.679674Z","shell.execute_reply.started":"2024-09-21T09:04:21.674599Z","shell.execute_reply":"2024-09-21T09:04:21.678608Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"100\n43\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_metric\nbleu_metric = load_metric(\"bleu\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    decoded_preds = [pred.split() for pred in decoded_preds]\n    decoded_labels = [[label.split()] for label in decoded_labels]  # BLEU expects a list of references for each prediction\n    \n    bleu_score = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n    return {\"bleu\": bleu_score['bleu']}","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:04:22.061405Z","iopub.execute_input":"2024-09-21T09:04:22.061773Z","iopub.status.idle":"2024-09-21T09:04:25.743353Z","shell.execute_reply.started":"2024-09-21T09:04:22.061737Z","shell.execute_reply":"2024-09-21T09:04:25.742496Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1138584447.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n  bleu_metric = load_metric(\"bleu\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.48k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6444134de574c95885525b258fc4f66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86e79dfba91046b9bd62de41ef05a303"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for bleu contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/bleu.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"}]},{"cell_type":"code","source":"# ******************************* 4 ******************************* \nfrom transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n\n# Define training arguments for multi-GPU and FP16\ntraining_args = TrainingArguments(\n    output_dir='./results_1',\n    num_train_epochs=9,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    save_steps=500,\n    save_total_limit=1,\n    logging_dir='./logs',\n    report_to='none',          # optional: to avoid logging issues with multiple GPUs\n    ddp_find_unused_parameters=True,  # required for multi-GPU\n    fp16=True,  \n)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n    )\n\n# Fine-tune the model\ntrainer.train()\n\n# eval_results = trainer.evaluate(eval_dataset=eval_dataset)\n# print(f\"BLEU score: {eval_results['eval_bleu']}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:19:42.609652Z","iopub.execute_input":"2024-09-21T09:19:42.610224Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='514' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [514/900 18:42 < 14:05, 0.46 it/s, Epoch 5.13/9]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.912900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Initialize an empty list to store evaluation results\neval_results = []\n\n# Set the small batch size for evaluation segments\nsmall_batch_size = 1  # Adjust as needed based on memory constraints\n\n# Create a DataLoader for the test dataset\neval_dataloader = DataLoader(test_dataset, batch_size=small_batch_size)\n\n# Evaluate the model on each small batch\nfor batch in eval_dataloader:\n    result = trainer.evaluation_loop(\n        dataloader=[batch],  # Pass the batch wrapped in a list\n        description=\"Evaluation\",\n        prediction_loss_only=True,  # Use if you don't want to compute other metrics\n    )\n\n    # Append the result for this batch to the list\n    eval_results.append(result)\n\n# Calculate the BLEU score by averaging over all batches\ntotal_bleu_score = sum(res['eval_bleu'] for res in eval_results if 'eval_bleu' in res) / len(eval_results)\n\n# Print the final BLEU score\nprint(f\"Final BLEU score: {total_bleu_score}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:09:28.143548Z","iopub.execute_input":"2024-09-21T09:09:28.144664Z","iopub.status.idle":"2024-09-21T09:10:13.401819Z","shell.execute_reply.started":"2024-09-21T09:09:28.144619Z","shell.execute_reply":"2024-09-21T09:10:13.400919Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='43' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 00:44]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Final BLEU score: 0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}